---
title: "Week 12 - The Office - Words and numbers"
output: html_notebook
---

```{r}
library(tidyverse)
library(schrute)

theme_set(theme_light())


office_transcripts <- as_tibble(theoffice) %>%
  mutate(season = as.integer(season),
         episode = as.integer(episode)) %>%
  mutate(character = str_remove_all(character, '"')) %>%
  mutate(name = str_to_lower(str_remove_all(episode_name, "\\.| \\(Part.*")))

office_ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv') %>%
    mutate(name = str_to_lower(str_remove(title, "\\.| \\(Part.*|\\: Part.*")))


View(office_ratings)

```

```{r}
## What`s the average rating by season?
office_ratings %>%
  group_by(season) %>%
  summarize(avg_rating = mean(imdb_rating)) %>%
  ggplot(aes(season, avg_rating)) +
    geom_line() +
  scale_x_continuous(breaks = 1:9)

```
```{r}
library(ggrepel)
## How about across episodes? Line chart + Point for each episode, text with overlap to show highest and lowest
## Banker = clip show
office_ratings %>%
  mutate(title = fct_inorder(title), episode_number = row_number()) %>%
  ggplot(aes(episode_number, imdb_rating)) + 
  geom_line() +
  geom_smooth() +
  geom_point(aes(color = factor(season), size = total_votes)) +
  geom_text(aes(label = title), check_overlap = TRUE) +
  expand_limits(x = -10) +
  theme(panel.grid.major.x = element_blank(),
        legend.position = 'None') +
  labs(x = "Episode Number",
       y = "IMDB Rating",
       title = "Popularity of Office episodes over time",
       subtitle = "Colour represents season, size represents total votes")
```
```{r}
# Most popular episodes
office_ratings %>%
  arrange(desc(imdb_rating)) %>%
  mutate(title = paste0(season, ".", episode, " ", title),
         title = fct_reorder(title, imdb_rating)) %>%
  head(20) %>%
  ggplot(aes(title, imdb_rating, color = factor(season), size = total_votes)) +
  geom_point() +
  coord_flip() +
  labs(colour = "Season",
       title = "Most popular episodes of The Office")
  
```

### Transcripts

```{r}
library(tidytext)

blocklist <- c("yeah", "hey", "uh", "gonna")
blocklist_characters <- c('Everyone', 'All', 'Both', 'Guy', 'Girl', 'Group')

transcript_words <- office_transcripts %>%
  group_by(character) %>%
  filter(n() >= 100,
         n_distinct(episode_name) > 2) %>%
  ungroup() %>%
  select(-text_w_direction) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = 'word') %>%
  filter(!word %in% blocklist,
         !character %in% blocklist_characters)
```

### Are there words specific to characters?

```{r}
## Filter to socre set of characters, a lot of characters in specific episodes with specific words

character_tf_idf <- transcript_words %>%
  add_count(word) %>%
  filter(n >= 20) %>%
  count(word, character) %>%
  bind_tf_idf(word, character, n) %>%
  arrange(desc(tf_idf))
```

### Look for main words for a few main characters

```{r}
 character_tf_idf %>% 
  filter(character == c("Dwight", "Jim", "David Wallace", "Darryl", "Jan", "Holly")) %>%
  group_by(character) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, tf_idf, character)) %>%
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  coord_flip() +
  scale_x_reordered() +
  facet_wrap(~ character, scales = "free_y") +
  labs(x = "",
       y = "TF-IDF of character-word pairs")

```

### Machine learning model

What affects popularity of an episode:

* Season / time
* Director
* Writer
* Lines per character

```{r}

ratings_summarized <- office_ratings %>%
  group_by(name) %>%
  summarize(imdb_rating = mean(imdb_rating))

character_lines_ratings <- office_transcripts %>%
  filter(!character %in% blocklist_characters) %>%
  count(character, name) %>%
  group_by(character) %>%
  filter(sum(n) >= 50,
         n() >= 5) %>%
  inner_join(ratings_summarized, by = 'name')


character_lines_ratings %>%
  summarize(avg_rating = mean(imdb_rating),
            nb_episodes = n()) %>%
  arrange(desc(avg_rating))
```


```{r}
## writer column can have multiple, we need to split them up, keep those with 3 credits to ensure a lot of data

director_writer_features <- office_transcripts %>%
  distinct(name, director, writer) %>%
  gather(type, value, director, writer) %>%
  separate_rows(value,sep = ';') %>%
  unite(feature, type, value, sep = ": ") %>%
  add_count(feature) %>%
  filter(n >= 3)

character_line_features <- character_lines_ratings %>%
  select(name, feature = character, value = n)

```

